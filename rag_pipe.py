import os
import json
from dotenv import load_dotenv

from langchain_upstage.embeddings import UpstageEmbeddings
from langchain_qdrant import QdrantVectorStore
from qdrant_client import QdrantClient

from langchain.prompts import PromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain_core.runnables import RunnableMap

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

UPSTAGE_API_KEY = os.getenv("UPSTAGE_API_KEY")
QDRANT_URL = os.getenv("QDRANT_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")

assert UPSTAGE_API_KEY, ".envì— UPSTAGE_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤."
assert QDRANT_URL and QDRANT_API_KEY, "Qdrant ì„¤ì •ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤."

# 2. Qdrant ì—°ê²° + ì„ë² ë”© ëª¨ë¸
embedding_model = UpstageEmbeddings(api_key=UPSTAGE_API_KEY, model="embedding-passage")
qdrant_client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)
vectorstore = QdrantVectorStore(
    client=qdrant_client,
    collection_name="dream-papers",
    embedding=embedding_model,
)

# 3. LLM ì„¤ì • (Upstage via OpenAI-compatible API)
llm = ChatOpenAI(
    openai_api_key=UPSTAGE_API_KEY,
    openai_api_base="https://api.upstage.ai/v1",
    model_name="solar-pro"
)

# 4. ì‚¬ìš©ì ê¿ˆ ì¼ê¸° ë¶ˆëŸ¬ì˜¤ê¸°
with open("dreams_with_emotions.json", "r", encoding="utf-8") as f:
    dreams = json.load(f)

# 5. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ë…¼ë¬¸ ë‚´ìš©ë§Œ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ë„ë¡ ê°•ì œ)
prompt_template = PromptTemplate(
    input_variables=["context", "question"],
    template="""
ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ê¿ˆ ì¼ê¸°ì…ë‹ˆë‹¤:
"{question}"

ë‹¤ìŒì€ Qdrantì—ì„œ ê²€ìƒ‰ëœ ê´€ë ¨ ë…¼ë¬¸ ë‚´ìš©ì…ë‹ˆë‹¤:
"{context}"

ìœ„ ë…¼ë¬¸ ë‚´ìš©ì„ ë°˜ë“œì‹œ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬ ì‚¬ìš©ìì˜ ì‹¬ë¦¬ ìƒíƒœë¥¼ í•´ì„í•´ì£¼ì„¸ìš”.

ğŸ“Œ ì•„ë˜ ê·œì¹™ì„ ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•©ë‹ˆë‹¤:
- ë…¼ë¬¸ì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ìœ ì¶”í•˜ì§€ ë§ˆì„¸ìš”.
- ë…¼ë¬¸ ì¶œì²˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„ì´ ì–´ë–»ê²Œ ì—°ê²°ë˜ëŠ”ì§€ ì„¤ëª…í•˜ì„¸ìš”.
- í—ˆìœ„ ì •ë³´ë¥¼ ë§Œë“¤ê±°ë‚˜ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.
- ì‘ë‹µì€ ë”°ëœ»í•˜ê³  ê³µê° ê°€ëŠ” ë§íˆ¬ë¡œ, ì‹¬ë¦¬í•™ì  ê´€ì ì—ì„œ í•´ì„í•´ì£¼ì„¸ìš”.
"""
)

# 6. RAG ì²´ì¸ êµ¬ì„± (Runnable ë°©ì‹)
rag_chain = (
    RunnableMap({
        "context": lambda x: "\n\n".join([doc.page_content for doc in x["input_documents"]]),
        "question": lambda x: x["question"]
    })
    | prompt_template
    | llm
)

# 7. ê¿ˆ í•´ëª½ ì‹¤í–‰
for i, dream in enumerate(dreams[:3]):
    query = dream["content"]
    print(f"\nğŸ” [ì‚¬ìš©ì ì§ˆë¬¸ {i+1}]: {dream['title']}")

    # ğŸ” Qdrant ë¬¸ì„œ ê²€ìƒ‰
    docs = vectorstore.as_retriever().get_relevant_documents(query)
    print(f"ğŸ“š ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(docs)}")

    # âœ… Qdrant ê²€ìƒ‰ ê²°ê³¼ í™•ì¸ (í…ŒìŠ¤íŠ¸ìš©)
    print("\nğŸ“„ ğŸ” ê²€ìƒ‰ëœ ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°:")
    for j, doc in enumerate(docs):
        print(f"ğŸ“„ ë¬¸ì„œ {j+1}: {doc.metadata.get('title')}")
        print(doc.page_content[:300], "\n---")

    # ğŸ§  í•´ëª½ ìƒì„±
    result = rag_chain.invoke({
        "input_documents": docs,
        "question": query
    })
    print("\nğŸ§  í•´ëª½ ì‘ë‹µ:")
    print(result.content if hasattr(result, 'content') else result)
