from qdrant_client import QdrantClient
from qdrant_client.models import Filter, FieldCondition, MatchValue, PointStruct, Distance, VectorParams
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from dream_symbol_analysis import analyze_symbols_and_intentions # ìƒì§•ê³¼ ì˜ë„ ë¶„ì„ì„ ìœ„í•œ ëª¨ë“ˆ ì„í¬íŠ¸
import requests
import torch
import os
import uuid

# ========== ì„¤ì • ==========
EMBEDDING_API_KEY = os.getenv("UPSTAGE_API_KEY")
QDRANT_URL = os.getenv("QDRANT_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")

# ê°ì • ë¶„ì„ ëª¨ë¸
model_name = "j-hartmann/emotion-english-distilroberta-base"
tokenizer = AutoTokenizer.from_pretrained(model_name)

def load_model():
    model = AutoModelForSequenceClassification.from_pretrained(model_name)
    model.half()  # FP16 ì ìš©
    model.eval()  # í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
    return model

emotion_labels = [
    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring',
    'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval',
    'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief',
    'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization',
    'relief', 'remorse', 'sadness', 'surprise', 'neutral'
]

#ê°ì • ë¶„ì„ api ê¸°ë³¸ ì„¸íŒ…
def analyze_emotions(text, threshold=0.3):
    inputs = tokenizer(text, return_tensors="pt", truncation=True)
    # ëª¨ë¸ í•„ìš”í•  ë•Œë§Œ ë¡œë”©
    model = load_model()
    with torch.no_grad():
        logits = model(**inputs).logits
    del model
    torch.cuda.empty_cache()
    probs = torch.sigmoid(logits).squeeze().tolist()
    results = [
        {"label": label, "score": round(score, 3)}
        for label, score in zip(emotion_labels, probs)
        if score > threshold
    ]
    return sorted(results, key=lambda x: x["score"], reverse=True)

# ===== í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í•  =====
def split_text_into_chunks(text, max_tokens=4000):
    approx_chunk_size = max_tokens * 4  # ì˜ì–´ ê¸°ì¤€ 1 token â‰ˆ 4 chars
    return [text[i:i+approx_chunk_size] for i in range(0, len(text), approx_chunk_size)]

# ì„ë² ë”© í‰ê·  ë‚´ì„œ ì´ ë¬¸ì„œì˜ ëŒ€í‘œ ë²¡í„°ë¡œ ì‚¬ìš©
def get_embedding(text):
    chunks = split_text_into_chunks(text)
    vectors = []

    for chunk in chunks:
        url = "https://api.upstage.ai/v1/solar/embeddings"
        headers = {
            'Authorization': f'Bearer {EMBEDDING_API_KEY}',
            'Content-Type': 'application/json'
        }
        payload = {
            "model": "embedding-passage",
            "input": text
        }
        response = requests.post(url, headers=headers, json=payload)

        if response.status_code != 200:
            print(f"[EMBED ERROR] {response.status_code} - {response.text}")
            return []

        try:
            vector = response.json()['data'][0]['embedding']
            del response
            vectors.append(vector)
        except Exception as e:
            print(f"[EMBED JSON ERROR] {e}")
            return []
    
    if not vectors:
        return []
    
    mean_vector = [sum(dim) / len(vectors) for dim in zip(*vectors)]
    return mean_vector


# ========== í•µì‹¬ ì‹¤í–‰ ==========
def process_qdrant_document(user_id: str, title: str):
    source_collection = f"dream-{user_id}"
    target_collection = f"dream-{user_id}-emotion"
    print(f"ğŸ” ë¶„ì„ ëŒ€ìƒ ì»¬ë ‰ì…˜: {source_collection}, íƒ€ì´í‹€: {title}")

    # Qdrant ì—°ê²°
    qdrant_client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)

    # collections ì¡´ì¬ í™•ì¸
    collections = [c.name for c in qdrant_client.get_collections().collections]
    if source_collection not in collections:
        print(f"âŒ ì»¬ë ‰ì…˜ '{source_collection}' ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    # titleì— í•´ë‹¹í•˜ëŠ” ëª¨ë“  í¬ì¸íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
    scroll_result = qdrant_client.scroll(
        collection_name = source_collection,
        scroll_filter=Filter(
            must=[
                FieldCondition(key="metadata.title", match=MatchValue(value=title))
            ]
        ),
        with_payload=True,
        limit=1000
    )

    points = scroll_result[0]
    if not points:
        print("í•´ë‹¹ titleì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # page_content í•©ì¹˜ê¸°
    combined_text = " ".join(p.payload.get("page_content", "") for p in points)

    # ê°ì • ë¶„ì„
    emotions = analyze_emotions(combined_text)
    # âœ… ìˆ˜ì •: ìƒì§•/ì˜ë„ í•´ì„ë„ ê°™ì´ ì‹¤í–‰ (GPT ìë™ ì¡°ê±´ë¶€ í¬í•¨)
    symbolic_result = analyze_symbols_and_intentions(combined_text)
    # ì„ë² ë”© ìƒì„±
    embedding = get_embedding(combined_text)

    if not embedding:
        print("âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
        return
    
    # ê°ì • ê²°ê³¼ ì €ì¥ìš© ì»¬ë ‰ì…˜ ì—†ìœ¼ë©´ ìƒì„±
    if target_collection not in collections:
        qdrant_client.recreate_collection(
            collection_name=target_collection,
            vectors_config=VectorParams(size=len(embedding), distance=Distance.COSINE)
        )
        print(f"âœ… ìƒˆë¡œìš´ ì»¬ë ‰ì…˜ ìƒì„±ë¨: {target_collection}")

    # í¬ì¸íŠ¸ ìƒì„± ë° ì—…ë¡œë“œ
    point = PointStruct(
        id=str(uuid.uuid4()),
        vector=embedding,
        payload={
            "user_id": user_id,
            "title": title,
            "emotions": emotions,
            "symbols": symbolic_result["symbols"],           #symbolê³¼ ì˜ë„ ë¶„ì„ ê²°ê³¼ ì¶”ê°€
            "intentions": symbolic_result["intentions"],
            "full_text": combined_text
        }
    )

    qdrant_client.upsert(collection_name=target_collection, points=[point])
    print(f"ğŸ“Œ '{target_collection}'ì— ê°ì • ë¶„ì„ ê²°ê³¼ ì—…ë¡œë“œ ì™„ë£Œ!")


# ========== ì˜ˆì‹œ ì‹¤í–‰ ==========
if __name__ == "__main__":
    user_id = input("ì‚¬ìš©ì ID ì…ë ¥: ").strip()
    title = input("ë¶„ì„í•  ë¬¸ì„œ title ì…ë ¥: ").strip()
    process_qdrant_document(user_id, title)
